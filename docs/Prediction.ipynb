{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Winning Football Team\n",
    "\n",
    "Can we design a predictive model capable of accurately predicting if the home team will win a football match? \n",
    "\n",
    "![alt text](https://6544-presscdn-0-22-pagely.netdna-ssl.com/wp-content/uploads/2017/04/English-Premier-League.jpg \"Logo Title Text 1\")\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. We will clean our dataset\n",
    "2. Split it into training and testing data (12 features & 1 target (winning team (Home/Away/Draw))\n",
    "3. Train 3 different classifiers on the data \n",
    "  -Logistic Regression\n",
    "  -Support Vector Machine \n",
    "  -XGBoost\n",
    "4. Use the best Classifer to predict who will win given an away team and a home team\n",
    "\n",
    "## History\n",
    "\n",
    "Sports betting is a 500 billion dollar market (Sydney Herald)\n",
    "\n",
    "![alt text](https://static1.squarespace.com/static/506a95bbc4aa0491a951c141/t/51a55d97e4b00f4428967e64/1369791896526/sports-620x349.jpg \"Logo Title Text 1\")\n",
    "\n",
    "Kaggle hosts a yearly competiton called March Madness \n",
    "\n",
    "https://www.kaggle.com/c/march-machine-learning-mania-2017/kernels\n",
    "\n",
    "Several Papers on this \n",
    "\n",
    "https://arxiv.org/pdf/1511.05837.pdf\n",
    "\n",
    "\"It is possible to predict the winner of English county twenty twenty cricket games in almost two thirds of instances.\"\n",
    "\n",
    "https://arxiv.org/pdf/1411.1243.pdf\n",
    "\n",
    "\"Something that becomes clear from the results is that Twitter contains enough information to be useful for\n",
    "predicting outcomes in the Premier League\"\n",
    "\n",
    "https://qz.com/233830/world-cup-germany-argentina-predictions-microsoft/\n",
    "\n",
    "For the 2014 World Cup, Bing correctly predicted the outcomes for all of the 15 games in the knockout round.\n",
    "\n",
    "So the right questions to ask are\n",
    "\n",
    "-What model should we use?\n",
    "-What are the features (the aspects of a game) that matter the most to predicting a team win? Does being the home team give a team the advantage? \n",
    "\n",
    "## Dataset\n",
    "\n",
    "- Football is played by 250 million players in over 200 countries (most popular sport globally)\n",
    "- The English Premier League is the most popular domestic team in the world\n",
    "- Retrived dataset from http://football-data.co.uk/data.php\n",
    "\n",
    "![alt text](http://i.imgur.com/YRIctyo.png \"Logo Title Text 1\")\n",
    "\n",
    "- Football is a team sport, a cheering crowd helps morale\n",
    "- Familarity with pitch and weather conditions helps\n",
    "- No need to travel (less fatigue)\n",
    "\n",
    "Acrononyms- https://rstudio-pubs-static.s3.amazonaws.com/179121_70eb412bbe6c4a55837f2439e5ae6d4e.html\n",
    "\n",
    "## Other repositories\n",
    "\n",
    "- https://github.com/rsibi/epl-prediction-2017 (EPL prediction)\n",
    "- https://github.com/adeshpande3/March-Madness-2017 (NCAA prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1d0fabb9bf1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;31m#produces a prediction model in the form of an ensemble of weak prediction models, typically decision tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;31m#the outcome (dependent variable) has only a limited number of possible values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;31m#Logistic Regression is used when response variable is categorical in nature.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "import pandas as pd\n",
    "#produces a prediction model in the form of an ensemble of weak prediction models, typically decision tree\n",
    "import xgboost as xgb\n",
    "#the outcome (dependent variable) has only a limited number of possible values. \n",
    "#Logistic Regression is used when response variable is categorical in nature.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#A random forest is a meta estimator that fits a number of decision tree classifiers \n",
    "#on various sub-samples of the dataset and use averaging to improve the predictive \n",
    "#accuracy and control over-fitting.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#a discriminative classifier formally defined by a separating hyperplane.\n",
    "from sklearn.svm import SVC\n",
    "#displayd data\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data and drop redundant column.\n",
    "data = pd.read_csv('final_dataset.csv')\n",
    "\n",
    "# Preview data.\n",
    "display(data.head())\n",
    "\n",
    "\n",
    "#Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "#HTGD - Home team goal difference\n",
    "#ATGD - away team goal difference\n",
    "#HTP - Home team points\n",
    "#ATP - Away team points\n",
    "#DiffFormPts Diff in points\n",
    "#DiffLP - Differnece in last years prediction\n",
    "\n",
    "#Input - 12 other features (fouls, shots, goals, misses,corners, red card, yellow cards)\n",
    "#Output - Full Time Result (H=Home Win, D=Draw, A=Away Win) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what is the win rate for the home team?\n",
    "\n",
    "# Total number of matches.\n",
    "n_matches = data.shape[0]\n",
    "\n",
    "# Calculate number of features. -1 because we are saving one as the target variable (win/lose/draw)\n",
    "n_features = data.shape[1] - 1\n",
    "\n",
    "# Calculate matches won by home team.\n",
    "n_homewins = len(data[data.FTR == 'H'])\n",
    "\n",
    "# Calculate win rate for home team.\n",
    "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
    "\n",
    "# Print the results\n",
    "print \"Total number of matches: {}\".format(n_matches)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Number of matches won by home team: {}\".format(n_homewins)\n",
    "print \"Win rate of home team: {:.2f}%\".format(win_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualising distribution of data\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "#the scatter matrix is plotting each of the columns specified against each other column.\n",
    "#You would have observed that the diagonal graph is defined as a histogram, which means that in the \n",
    "#section of the plot matrix where the variable is against itself, a histogram is plotted.\n",
    "\n",
    "#Scatter plots show how much one variable is affected by another. \n",
    "#The relationship between two variables is called their correlation\n",
    "#negative vs positive correlation\n",
    "\n",
    "#HTGD - Home team goal difference\n",
    "#ATGD - away team goal difference\n",
    "#HTP - Home team points\n",
    "#ATP - Away team points\n",
    "#DiffFormPts Diff in points\n",
    "#DiffLP - Differnece in last years prediction\n",
    "\n",
    "scatter_matrix(data[['HTGD','ATGD','HTP','ATP','DiffFormPts','DiffLP']], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate into feature set and target variable\n",
    "#FTR = Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "X_all = data.drop(['FTR'],1)\n",
    "y_all = data['FTR']\n",
    "\n",
    "# Standardising the data.\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#Center to the mean and component wise scale to unit variance.\n",
    "cols = [['HTGD','ATGD','HTP','ATP','DiffLP']]\n",
    "for col in cols:\n",
    "    X_all[col] = scale(X_all[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#last 3 wins for both sides\n",
    "X_all.HM1 = X_all.HM1.astype('str')\n",
    "X_all.HM2 = X_all.HM2.astype('str')\n",
    "X_all.HM3 = X_all.HM3.astype('str')\n",
    "X_all.AM1 = X_all.AM1.astype('str')\n",
    "X_all.AM2 = X_all.AM2.astype('str')\n",
    "X_all.AM3 = X_all.AM3.astype('str')\n",
    "\n",
    "#we want continous vars that are integers for our input data, so lets remove any categorical vars\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the football data and converts catagorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)\n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the feature information by printing the first five rows\n",
    "print \"\\nFeature values:\"\n",
    "display(X_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Shuffle and split the dataset into training and testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                    test_size = 50,\n",
    "                                                    random_state = 2,\n",
    "                                                    stratify = y_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for measuring training time\n",
    "from time import time \n",
    "# F1 score (also F-score or F-measure) is a measure of a test's accuracy. \n",
    "#It considers both the precision p and the recall r of the test to compute \n",
    "#the score: p is the number of correct positive results divided by the number of \n",
    "#all positive results, and r is the number of correct positive results divided by \n",
    "#the number of positive results that should have been returned. The F1 score can be \n",
    "#interpreted as a weighted average of the precision and recall, where an F1 score \n",
    "#reaches its best value at 1 and worst at 0.\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print \"Trained model in {:.4f} seconds\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    \n",
    "    end = time()\n",
    "    # Print and return results\n",
    "    print \"Made predictions in {:.4f} seconds.\".format(end - start)\n",
    "    \n",
    "    return f1_score(target, y_pred, pos_label='H'), sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print \"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print f1, acc\n",
    "    print \"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc)\n",
    "    \n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print \"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/logisticregression-predictingthechancesofcoronaryheartdisease-091203130638-phpapp01/95/logistic-regression-predicting-the-chances-of-coronary-heart-disease-2-728.jpg?cb=1259845609\"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://i.ytimg.com/vi/HdB-z0TJRK4/maxresdefault.jpg \"Logo Title Text 1\")\n",
    "\n",
    "Support Vector Machine\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/supportvectormachine-121112135318-phpapp01/95/support-vector-machine-3-638.jpg?cb=1352729591 \"Logo Title Text 1\")\n",
    "![alt text](http://docs.opencv.org/2.4/_images/optimal-hyperplane.png \"Logo Title Text 1\")\n",
    "\n",
    "XGBoost\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/cart.png \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/twocart.png \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/0782ee51-165d-4e34-a09c-2b7f8dacff01-150403064822-conversion-gate01/95/feature-importance-analysis-with-xgboost-in-tax-audit-17-638.jpg?cb=1450092771 \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/0782ee51-165d-4e34-a09c-2b7f8dacff01-150403064822-conversion-gate01/95/feature-importance-analysis-with-xgboost-in-tax-audit-18-638.jpg?cb=1450092771 \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the three models (XGBoost is initialized later)\n",
    "clf_A = LogisticRegression(random_state = 42)\n",
    "clf_B = SVC(random_state = 912, kernel='rbf')\n",
    "#Boosting refers to this general problem of producing a very accurate prediction rule \n",
    "#by combining rough and moderately inaccurate rules-of-thumb\n",
    "clf_C = xgb.XGBClassifier(seed = 82)\n",
    "\n",
    "train_predict(clf_A, X_train, y_train, X_test, y_test)\n",
    "print ''\n",
    "train_predict(clf_B, X_train, y_train, X_test, y_test)\n",
    "print ''\n",
    "train_predict(clf_C, X_train, y_train, X_test, y_test)\n",
    "print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clearly XGBoost seems like the best model as it has the highest F1 score and accuracy score on the test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the parameters of XGBoost.\n",
    "\n",
    "![alt text](https://i.stack.imgur.com/9GgQK.jpg \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Import 'GridSearchCV' and 'make_scorer'\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune\n",
    "parameters = { 'learning_rate' : [0.1],\n",
    "               'n_estimators' : [40],\n",
    "               'max_depth': [3],\n",
    "               'min_child_weight': [3],\n",
    "               'gamma':[0.4],\n",
    "               'subsample' : [0.8],\n",
    "               'colsample_bytree' : [0.8],\n",
    "               'scale_pos_weight' : [1],\n",
    "               'reg_alpha':[1e-5]\n",
    "             }  \n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = xgb.XGBClassifier(seed=2)\n",
    "\n",
    "# TODO: Make an f1 scoring function using 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score,pos_label='H')\n",
    "\n",
    "# TODO: Perform grid search on the classifier using the f1_scorer as the scoring method\n",
    "grid_obj = GridSearchCV(clf,\n",
    "                        scoring=f1_scorer,\n",
    "                        param_grid=parameters,\n",
    "                        cv=5)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "print clf\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "f1, acc = predict_labels(clf, X_train, y_train)\n",
    "print \"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc)\n",
    "    \n",
    "f1, acc = predict_labels(clf, X_test, y_test)\n",
    "print \"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Improvements?\n",
    "\n",
    "-Adding Sentiment from Twitter, News Articles\n",
    "-More features from other data sources (how much did others bet, player specific health stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
